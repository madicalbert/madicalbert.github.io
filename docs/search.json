[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Portfolio",
    "section": "",
    "text": "Benefits Transfer\n\n\n\nR\n\n\nCost Benefit Analysis\n\n\nBenefits Transfer\n\n\n\nEstimating restoration costs and storm protection benefits for 60 hectares of salt marsh habitat in Huntington Beach, CA using benefits transfer.\n\n\n\nMadison Calbert\n\n\nDec 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHabitat Connectivity\n\n\n\nGIS\n\n\nConservation Planning\n\n\nHabitat Connectvity\n\n\nModeling\n\n\n\nMapping Habitat Connectivity and Potential Jaguar Movement Pathways in Costa Rica using Circuitscape\n\n\n\nMadison Calbert and Olivia Hemond\n\n\nSep 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConservation Network Design\n\n\n\nGIS\n\n\nConservation Planning\n\n\nNetwork Design\n\n\n\nAssessing the Potential for Raptors as Umbrella Species for Reserve Network Design in Morro Bay\n\n\n\nMadison Calbert and Olivia Hemond\n\n\nSep 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHabitat Suitability\n\n\n\nGIS\n\n\nConservation Planning\n\n\nHabitat Suitability\n\n\nModeling\n\n\n\nModeling African Lion Habitat Ranges using Maxent across Climate Change Scenarios\n\n\n\nMadison Calbert and Natalie Smith\n\n\nSep 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBiodiversity Hotspots\n\n\n\nGIS\n\n\nConservation Planning\n\n\nHabitat Suitability\n\n\nModeling\n\n\n\nHotspots and Coldspots for Sea Lions (Zalophus californianus and Eumetopias jubatus)\n\n\n\nMadison Calbert and Natalie Smith\n\n\nSep 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBinary Logistic Regression\n\n\n\nR\n\n\nModeling\n\n\nRegression\n\n\nCross-Validation\n\n\nData Visualization\n\n\n\nUsing binary logistic regression to differentiate plant species.\n\n\n\nMadison Calbert\n\n\nMar 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNon-linear Least Squares\n\n\n\nR\n\n\nModeling\n\n\nData Visualization\n\n\n\nDescribing and predicting crop yields using non-linear least squares regression models.\n\n\n\nMadison Calbert\n\n\nMar 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpatial Data Analysis\n\n\n\nR\n\n\nGeospatial\n\n\nData Visualization\n\n\n\nAnalyzing the spatial distribution of oil spill incidents in California from 2008.\n\n\n\nMadison Calbert\n\n\nFeb 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nText Sentiment Analysis\n\n\n\nR\n\n\nSentiment Analysis\n\n\nData Visualization\n\n\n\nExtracting text and performing sentiment analysis on Steinbeck’s East of Eden\n\n\n\nMadison Calbert\n\n\nFeb 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTime Series Analysis\n\n\n\nR\n\n\nTime Series\n\n\nData Visualization\n\n\n\nAssessing temporal patterns of salmon and steelhead trout in the Willamette Falls Fish Passage from 2001 to 2010.\n\n\n\nMadison Calbert\n\n\nFeb 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling and Visualization\n\n\n\nR\n\n\nData Visualization\n\n\n\nExploring mountain yellow-legged frog (Rana muscosa) abundance in Sierra Lakes from 1995 - 2002.\n\n\n\nMadison Calbert\n\n\nFeb 2, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I am currently a master’s student at UC Santa Barbara’s Bren School of Environmental Science & Management, specializing in conservation planning. Before graduate school, I worked as a consulting wildlife biologist and botanist, conducting special-status species surveys, botanical assessments, and biological construction monitoring. My experience spans a variety of taxa, including the federally and state-listed California tiger salamander (Ambystoma californiense) and California red-legged frog (Rana draytonii). I have also contributed to habitat restoration projects focused on invasive species removal and native plant installation. I earned a B.S. in Environmental Studies with an emphasis in ecology from UCSB. My passion for the natural world was shaped by my upbringing in Valley Center, a small, rural community in northern San Diego County. In my free time, I enjoy birdwatching, botanizing, hiking, and traveling with friends and family."
  },
  {
    "objectID": "about.html#professional-affiliations",
    "href": "about.html#professional-affiliations",
    "title": "About Me",
    "section": "Professional Affiliations",
    "text": "Professional Affiliations\nCalifornia Native Plant Society | The Wildlife Society"
  },
  {
    "objectID": "posts/2024-02-02-data-viz/index.html",
    "href": "posts/2024-02-02-data-viz/index.html",
    "title": "Data Wrangling and Visualization",
    "section": "",
    "text": "Adult Mountain yellow-legged frog in San Gabriel Mountains, Los Angeles County, CA. Photo Credit: Gary Nafis."
  },
  {
    "objectID": "posts/2024-02-02-data-viz/index.html#overview",
    "href": "posts/2024-02-02-data-viz/index.html#overview",
    "title": "Data Wrangling and Visualization",
    "section": "Overview",
    "text": "Overview\nThis report explores Mountain yellow-legged frog (Rana muscosa, RAMU) amphibian abundance data recorded by the Sierra Lakes Inventory Project. From the Environmental Data Initiative repository: “The Sierra Lakes Inventory Project (SLIP) was a research endeavor that ran from 1995-2002 and has supported research and management of Sierra Nevada aquatic ecosystems and their terrestrial interfaces. We described the physical characteristics of and surveyed aquatic communities for &gt;8,000 lentic water bodies in the southern Sierra Nevada, including lakes, ponds, marshes, and meadows.”"
  },
  {
    "objectID": "posts/2024-02-02-data-viz/index.html#ramu-abundance-by-year-and-life-stage-across-all-lakes",
    "href": "posts/2024-02-02-data-viz/index.html#ramu-abundance-by-year-and-life-stage-across-all-lakes",
    "title": "Data Wrangling and Visualization",
    "section": "RAMU Abundance by Year and Life Stage (across all lakes)",
    "text": "RAMU Abundance by Year and Life Stage (across all lakes)\n\nSteps\n\nLibraries\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(here)\nlibrary(patchwork)\nlibrary(lubridate)\nlibrary(readxl)\nlibrary(janitor)\n\n\n\nLoad in the data.\nFilter for Rana muscosa and life stage. Lubridate to edit date and make year a factor.\nGroup by life stage and year and summarize to find Rana muscosa abundance.\n\n\n\nCode\nfrog_ds &lt;- read_excel(here('posts', '2024-02-02-data-viz','data', 'sierra_amphibians.xlsx')) %&gt;% \n  clean_names()\n\n\nramu_ds &lt;- frog_ds %&gt;% \n  select('survey_date', 'amphibian_species', 'amphibian_life_stage', 'amphibian_number') %&gt;% \n  filter(amphibian_species == 'RAMU', amphibian_life_stage != 'EggMass') %&gt;% \n  mutate(year = lubridate::year(survey_date))\n\n\nramu_ds$year &lt;- factor(ramu_ds$year)\n\n\nramu_count &lt;- ramu_ds %&gt;% \n  group_by(amphibian_life_stage, year) %&gt;% \n  summarise(amphibian_number = sum(amphibian_number, na.rm = TRUE)) %&gt;% \n  ungroup()\n\n\n\nPlot Rana muscosa abundance by life stage for each year.\n\n\n\nCode\nyear_plot &lt;- ggplot(data = ramu_count, aes(x = year, y = amphibian_number, fill = amphibian_life_stage)) + \n  geom_col() +\n  scale_fill_manual(values = c(\"darkgreen\", \"lightgreen\", \"#FED976\"))+\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 10))+\n  labs(x = '',\n       y = 'Number of Amphibians',\n       fill = \"Life Stage\") + \n  theme_minimal()+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n  #scale_y_log10() -- decided not to put it on the log scale"
  },
  {
    "objectID": "posts/2024-02-02-data-viz/index.html#ramu-abundance-by-lake-and-life-stage-across-all-years",
    "href": "posts/2024-02-02-data-viz/index.html#ramu-abundance-by-lake-and-life-stage-across-all-years",
    "title": "Data Wrangling and Visualization",
    "section": "RAMU Abundance by Lake and Life stage (across all years)",
    "text": "RAMU Abundance by Lake and Life stage (across all years)\n\nSteps\n\nFilter for Rana muscosa and life stage (adult and sub-adult only). Lubridate to edit date.\nGroup by life stage (adult and sub-adult) and lake and summarize to find Rana muscosa abundance. Find the top 5 lakes with the greatest RAMU abundance.\n\n\n\nCode\nadult_ds &lt;-frog_ds %&gt;% \n  select('survey_date', 'amphibian_species', 'amphibian_life_stage', 'amphibian_number', 'lake_id') %&gt;% \n  filter(amphibian_species == 'RAMU', \n         amphibian_life_stage != 'EggMass', \n         amphibian_life_stage != 'Tadpole') %&gt;% \n  mutate(year = lubridate::year(survey_date))\n\n\nadult_counts &lt;- adult_ds %&gt;% \n  group_by(lake_id) %&gt;% \n  summarise(amphibian_number = sum(amphibian_number, na.rm = TRUE)) %&gt;% \n  ungroup()\n\n\ntop_frogs &lt;- adult_counts %&gt;% top_n(5, wt = amphibian_number) %&gt;% \n  mutate(lake_id = paste(\"Lake\", lake_id, sep = \" \")) %&gt;% \n  mutate(lake_id = fct_reorder(lake_id, amphibian_number))\n\n\n\nPlot the RAMU abundance in the top 5 lakes.\n\n\n\nCode\nlake_plot &lt;- ggplot(data = top_frogs, aes(x = lake_id, y = amphibian_number)) + \n  geom_col(fill = \"#3CB371\") +\n  labs(x = '',\n       y = 'Number of Amphibians',\n       title = expression(\" \"),\n       subtitle = 'Adult + Subadult combined') +\n  theme_minimal()+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\nPut the Figure all together and make it pretty.\n\n\n\nCode\nfigure_1 &lt;- year_plot + lake_plot\nfigure_1 + plot_annotation(tag_levels = \"A\", title = \"Mountain yellow-legged frog Abundance\")\n\n\n\n\n\nFigure 1: Mountain yellow-legged frog (RAMU, Rana muscosa) Abundance. Plot A portrays RAMU abundance by year and life stages (adult, subadult, and tadpole) across all lakes. RAMU abundance increases over the years and the tadpoles account for the greatest number of amphibians across all years. In 2002, there is the greatest number of tadpoles. Plot B portrays RAMU abundance by lake and life stage (adult and subadult combined) across all years, including the top 5 lakes with the greatest species abundance."
  },
  {
    "objectID": "posts/2024-02-02-data-viz/index.html#works-cited",
    "href": "posts/2024-02-02-data-viz/index.html#works-cited",
    "title": "Data Wrangling and Visualization",
    "section": "Works Cited",
    "text": "Works Cited\nKnapp, R.A., C. Pavelka, E.E. Hegeman, and T.C. Smith. 2020. The Sierra Lakes Inventory Project: Non-Native fish and community composition of lakes and ponds in the Sierra Nevada, California ver 2. Environmental Data Initiative. https://doi.org/10.6073/pasta/d835832d7fd00d9e4466e44eea87fab3"
  },
  {
    "objectID": "posts/2024-03-03-nonlinear-least-squares/index.html",
    "href": "posts/2024-03-03-nonlinear-least-squares/index.html",
    "title": "Non-linear Least Squares",
    "section": "",
    "text": "Cultivated grain sorghum, El Campo, Texas, 2013. Photo by Lance Cheung, USDA (USDA on flickr, public domain).."
  },
  {
    "objectID": "posts/2024-03-03-nonlinear-least-squares/index.html#overview",
    "href": "posts/2024-03-03-nonlinear-least-squares/index.html#overview",
    "title": "Non-linear Least Squares",
    "section": "Overview",
    "text": "Overview\n\nPurpose\nFarmers need to understand the biology of plants and their responses to fertilizers to maximize yield. In this report, I conduct non-linear least squares on experimental growth data for three grains in Greece to make predictions on their yields. Because many crop and soil processes are better represented by nonlinear models comapred to linear models, nonlinear regression models are used to explore this data.\n\n\nData Source\n“We used data from Danalatos et al. (2009), which represent destructive measurements of aboveground biomass accumulation with time for three crops: fiber sorghum (F), sweet sorghum (S), and maize (M), growing in a deep fertile loamy soil of central Greece under two management practices: high and low input conditions, in 2008.” (Archontoulis 2015). The data used in this report was accessed by installing the “nlraa” package and then using library(nlraa).\nArchontoulis, S.V. and Miguez, F.E. (2015). Nonlinear Regression Models and Applications in Agricultural Research. Agronomy Journal, Volume 107, Issue 2. Retreived from: https://acsess.onlinelibrary.wiley.com/doi/10.2134/agronj2012.0506\n\n\nData Summary\nThe five variables in the dataset are Day of the Year (DOY), Block, Input, Crop, and Biomass yield in Mg/ha. The data variables are described as follows:\n\nYield = harvested biomass for three crops\nCrop = types of crop: maize (M), fiber sorghum (F) and sweet sorghum (S).\nInput = two levels of agronomic input, level 1 (Low) or 2 (High)\nBlock = four blocks in the experimental design (1, 2, 3, or 4)\nDOY = “day of year”"
  },
  {
    "objectID": "posts/2024-03-03-nonlinear-least-squares/index.html#pseudocode",
    "href": "posts/2024-03-03-nonlinear-least-squares/index.html#pseudocode",
    "title": "Non-linear Least Squares",
    "section": "PseudoCode",
    "text": "PseudoCode\n\nLoad libraries, load data, clean/tidy the data\nRun nls on one crop (Sorghum)\n\nModel Selection\nCreate R Function\nDefine initial Guess\nRun NLS\nEvaluate Results\n\nUse purrr to run NLS models for all 24 combinations of plot\nMake a “good looking” table\n\n\n\nCode\nlibrary(nlraa)\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\nlibrary(Metrics)\nlibrary(cowplot)\nlibrary(nlme)\nlibrary(kableExtra)\nlibrary(purrr)\nlibrary(knitr)\nlibrary(patchwork)\n\n# glimpse(sm)\n\ndata &lt;- sm %&gt;% \n  clean_names()"
  },
  {
    "objectID": "posts/2024-03-03-nonlinear-least-squares/index.html#model-selection",
    "href": "posts/2024-03-03-nonlinear-least-squares/index.html#model-selection",
    "title": "Non-linear Least Squares",
    "section": "Model Selection",
    "text": "Model Selection\nI use the Beta function:\nY = Ymax (1 + (tc - t)/(tc - tm))(t/tc)^(tc / (tc - tm))\n“This model was selected because it captures the decline of biomass toward the end of the growing season and supplementary figure for the beta growth function. Also, the parameters have clear meaning and are very suitable to answer the research questions.” (Archontoulis 2015).\nThe parameters are defined as:\n\nY is the response variable (e.g., biomass)\nt is the explanatory variable (e.g., time),\nYasym or Ymax is the asymptotic or the maximum Y value, respectively,\ntm is the inflection point at which the growth rate is maximized,\nk controls the steepness of the curve,\nv deals with the asymmetric growth (if v = I, then Richards’ equation becomes logistic),\na and b are parameters that determine the shape of the curve,\nte is the time when Y = Yasym\ntc is the critical time for a switch-off to occur (eg., critical photoperiod),\nn is a parameter that determines the sharpness of the response\n\n\n\nCode\n### build a function\n\nbeta &lt;- function(doy, t_e, t_m, y_max){\n  out = y_max * (1 + (t_e - doy)/ (t_e - t_m)) * (doy/t_e)^(t_e/(t_e - t_m))\n  return(out)\n}\n\ny_max_guess &lt;- 20 \nt_e_guess &lt;- 240\nt_m_guess &lt;- 200\n\n\nguess &lt;- ggplot(data = data, aes(x = doy, y = yield, shape = crop)) + \n  geom_point() +\n  geom_smooth() +\n  facet_wrap(~input, labeller = labeller(input = c(\"2\" = \"High\", \"1\" = \"Low\"))) + \n  labs(x = \"Day of the Year\",\n       y = \" Dry biomass (Mg/ha)\",\n       shape = \"Crop\") +\n  theme_bw()"
  },
  {
    "objectID": "posts/2024-03-03-nonlinear-least-squares/index.html#one-crop-nls",
    "href": "posts/2024-03-03-nonlinear-least-squares/index.html#one-crop-nls",
    "title": "Non-linear Least Squares",
    "section": "One Crop NLS",
    "text": "One Crop NLS\nAfter defining the model, building a function, and making initial guesses, I now run the NLS on one crop: the high input sweet sorghum (S) crop. The selected parameter values, standard errors, and p-values of the estimated parameters are displayed in Table 1.\n\n\nCode\n### Sorghum Fields w/ High Inputs \n\nsm_high &lt;- data %&gt;% filter(crop == \"S\" & input == \"2\")\n\nsm_nls = nls(formula = yield ~ beta(doy, t_e, t_m, y_max), \n               data = sm_high, \n               start = list(t_e = t_e_guess, t_m = t_m_guess, y_max = y_max_guess), \n               trace = FALSE)\n\nsm_nls %&gt;%\n  broom::tidy() %&gt;%\n  mutate(p.value = ifelse(p.value &lt;= 0.05, \"&lt;0.05\")) %&gt;%\n  kbl(digits = 2, align = NULL) %&gt;%\n  kable_classic() \n\n\n\n\n\n\nterm\n\n\nestimate\n\n\nstd.error\n\n\nstatistic\n\n\np.value\n\n\n\n\n\n\nt_e\n\n\n281.59\n\n\n2.08\n\n\n135.33\n\n\n&lt;0.05\n\n\n\n\nt_m\n\n\n244.78\n\n\n3.51\n\n\n69.70\n\n\n&lt;0.05\n\n\n\n\ny_max\n\n\n39.82\n\n\n2.25\n\n\n17.71\n\n\n&lt;0.05\n\n\n\n\nTable 1: The selected parameter values, standard errors, and p-values of the estimated parameters for NLS on the high input sweet sorghum (S) crop.\n\n\n\n\nCode\nsm_p2 &lt;- sm_high %&gt;%\n  mutate(predict = predict(sm_nls, newdata=.))\n\nggplot(sm_p2, aes(x = doy, y = yield)) +\n  geom_point() +\n  geom_line(aes(x = doy, y = predict), linewidth = 1, color = \"red\")+ \n  labs(x = \"Day of the Year\",\n       y = \" Dry biomass (Mg/ha)\",\n       color = \"Crop\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nFigure 1: The fitted model on top of the the high input sweet sorghum (S) crop data."
  },
  {
    "objectID": "posts/2024-03-03-nonlinear-least-squares/index.html#nls-for-all-using-purrr",
    "href": "posts/2024-03-03-nonlinear-least-squares/index.html#nls-for-all-using-purrr",
    "title": "Non-linear Least Squares",
    "section": "NLS for All (using purrr)",
    "text": "NLS for All (using purrr)\nNow I run the NLS models for all 24 combinations of plot, input level, and crop type using purrr. Table 2 portrays the RMSE and chosen parameter values of the best fitted models for each species.\n\n\nCode\n### define a function for NLS for all\n\ncrop &lt;- function(nls_test){\n  nls(yield ~ beta(doy, t_e, t_m, y_max), \n  data = nls_test, \n  start = list(t_e = t_e_guess, t_m = t_m_guess, y_max = y_max_guess))\n}\n\n### purrr\n\nyield_all &lt;- data %&gt;%\n  group_by(block, input, crop) %&gt;%\n  nest() %&gt;%\n  mutate(nls_model = map(data,~crop(.x))) %&gt;%\n  mutate(predictions = map2(nls_model, data, ~predict(.x, newdata = .y))) %&gt;%\n  mutate(rmse = map2_dbl(predictions, data, ~ Metrics::rmse(.x, .y$yield))) %&gt;%\n  mutate(smooth = map(nls_model, ~predict(.x, newdata = list(doy = seq(147, 306)))))\n\n\n\n\nCode\nrmse_table &lt;- yield_all %&gt;% \n  group_by(crop) %&gt;% \n  summarise(rmse = min(rmse))\n\nlow_rmse &lt;- yield_all %&gt;% \n  filter(rmse %in% rmse_table$rmse)\n\nlow_rmse_M &lt;- broom::tidy(low_rmse$nls_model[[1]]) %&gt;% \n  mutate(crop = \"Maize(M)\")\n\n\nlow_rmse_S &lt;- broom::tidy(low_rmse$nls_model[[2]]) %&gt;% \n  mutate(crop = \"Sweet Sorghum (S))\")\n\n\nlow_rmse_F &lt;- broom::tidy(low_rmse$nls_model[[3]]) %&gt;% \n  mutate(crop = \"Fiber Sorgum (F)))\")\n\nlow_rmse_combined &lt;- bind_rows(low_rmse_M, low_rmse_S, low_rmse_F)\n\nlow_rmse_combined &lt;- low_rmse_combined[, c(\"crop\", setdiff(names(low_rmse_combined), \"crop\"))]\n\nlow_rmse_combined %&gt;%\n  kbl(digits = 2, align = NULL) %&gt;%\n  kable_classic() \n\n\n\n\n\n\ncrop\n\n\nterm\n\n\nestimate\n\n\nstd.error\n\n\nstatistic\n\n\np.value\n\n\n\n\n\n\nMaize(M)\n\n\nt_e\n\n\n252.57\n\n\n1.87\n\n\n135.13\n\n\n0\n\n\n\n\nMaize(M)\n\n\nt_m\n\n\n225.23\n\n\n1.93\n\n\n116.92\n\n\n0\n\n\n\n\nMaize(M)\n\n\ny_max\n\n\n18.93\n\n\n0.84\n\n\n22.55\n\n\n0\n\n\n\n\nSweet Sorghum (S))\n\n\nt_e\n\n\n278.35\n\n\n1.82\n\n\n153.18\n\n\n0\n\n\n\n\nSweet Sorghum (S))\n\n\nt_m\n\n\n245.77\n\n\n3.82\n\n\n64.42\n\n\n0\n\n\n\n\nSweet Sorghum (S))\n\n\ny_max\n\n\n31.35\n\n\n2.05\n\n\n15.31\n\n\n0\n\n\n\n\nFiber Sorgum (F)))\n\n\nt_e\n\n\n280.43\n\n\n1.84\n\n\n152.49\n\n\n0\n\n\n\n\nFiber Sorgum (F)))\n\n\nt_m\n\n\n245.00\n\n\n3.54\n\n\n69.24\n\n\n0\n\n\n\n\nFiber Sorgum (F)))\n\n\ny_max\n\n\n29.06\n\n\n1.66\n\n\n17.53\n\n\n0\n\n\n\n\nTable 2: The RMSE and chosen parameter values of the best fitted models for each species – fiber sorghum (F), sweet sorghum (S), and maize (M).\n\n\n\n\nCode\n# Unnest predictions from data and clean maize data\nun_df &lt;- yield_all %&gt;% \n  filter(block==1) %&gt;% \n  tidyr::unnest(smooth) %&gt;% \n  mutate(doy=seq(147,306)) %&gt;% \n  filter(!(doy&gt;263 & crop==\"M\"))\n\n# Create a dataframe to add corn data\nhi_filter &lt;- data %&gt;% \n  filter(block == 1 & input == 2)\n\nlow_filter &lt;- data %&gt;% \n  filter(block == 1 & input == 1)\n\n\n\n\nCode\n# Make graphs\nhi_plot &lt;- un_df %&gt;%\n  filter(block == 1 & input == 2) %&gt;%\n  ggplot() +\n  geom_point(data = hi_filter, aes(x = doy, y = yield, shape = crop)) +\n  geom_line(aes(x = doy, y = smooth, linetype = crop)) +labs(y = \" \", x = \"DOY\", color = \" \")+\n  theme_minimal()\n\n# hi_plot\n\n\nlow_plot&lt;-un_df |&gt; \n  filter(block==1 & input==1) |&gt; \n  ggplot()+\n  geom_point(data=low_filter,aes(x=doy,y=yield,shape=crop))+\n  geom_line(aes(x=doy,y=smooth,linetype=crop))+\n  labs(y = \"Biomass Yield\", x = \"DOY\", color = \"\")+\n  theme_minimal()\n\n# low_plot\n\n\ncombined_plot &lt;- low_plot + hi_plot\n\ncombined_plot + plot_layout(guides = \"collect\") + plot_annotation(tag_levels = \"A\")\n\n\n\n\n\nFigure 2: Observed data and fit for the final model for three crops: maize (M), fiber sorghum (F), and sweet sorghum (S) within Block 1. Plot A is the low input crops and Plot B is the high input crops."
  },
  {
    "objectID": "posts/2024-02-02-time-series/index.html",
    "href": "posts/2024-02-02-time-series/index.html",
    "title": "Time Series Analysis",
    "section": "",
    "text": "Coho Salmon. Photo Credit: Native Fish Society."
  },
  {
    "objectID": "posts/2024-02-02-time-series/index.html#overview",
    "href": "posts/2024-02-02-time-series/index.html#overview",
    "title": "Time Series Analysis",
    "section": "Overview",
    "text": "Overview\nThis report describes the abundance of three species of fish (coho salmon, jack coho salmon, and steel-head salmon) from 2001 to 2010 in the Willamette Falls fish ladder passage on the Willamette river in Oregon. The abundance of salmon is visualized over the 10 year study for each species and by the total counts of each species for each year. Trends and seasonality in salmon abundance between species are discussed in this report."
  },
  {
    "objectID": "posts/2024-02-02-time-series/index.html#part-1-original-time-series",
    "href": "posts/2024-02-02-time-series/index.html#part-1-original-time-series",
    "title": "Time Series Analysis",
    "section": "Part 1: Original time series",
    "text": "Part 1: Original time series\nOver the last 10 years, salmon abundance in the Willamette Falls fish passage has clear seasonality and oscillations for the three species. Coho salmon abundance has increased over the 10 year span, while Jack-coho and steelhead remained consistent as shown in Figure 1, Plot A. In any given year, coho and jack-coho salmon abundances peak in the fall months (Sept - Nov) and the steelhead salmon abundance peaks in the summer (May - July) as shown in Figure 1, Plot B.\n\nSteps\n\nLibraries\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(here)\nlibrary(patchwork)\nlibrary(lubridate)\nlibrary(janitor)\nlibrary(tsibble)\nlibrary(feasts)\nlibrary(fable)\nlibrary(RColorBrewer)\n\n\n\nLoad and tidy data\nMake into a time series\nPivot longer\n\n\n\nCode\nfish_df &lt;- read_csv(here('posts', '2024-02-02-time-series','data', 'willamette_fish_passage.csv')) %&gt;% \n  clean_names()\n\nsalmon_df &lt;- fish_df %&gt;% \n  select('project', 'date', 'coho', 'jack_coho', 'steelhead') %&gt;% \n  replace_na(replace = list(coho = 0, jack_coho = 0, steelhead = 0))\n\nsalmon_ts &lt;- salmon_df %&gt;% \n  mutate(date = lubridate::mdy(date)) %&gt;% \n  as_tsibble(key = NULL, \n             index = date)\n\nsalmon_ts_pivot &lt;- salmon_ts %&gt;% \n  pivot_longer(cols = c('coho', 'jack_coho', 'steelhead'),\n                 names_to = \"species\",\n                 values_to = \"count\") \n\n\n\nMake a pretty plot\n\n\n\nCode\nplot_ts &lt;- ggplot(data = salmon_ts_pivot, aes(x = date, y = count, color = species)) +\n  geom_line() + \n  labs(x = \" \",\n       y = 'Abundance',\n       color = \"Species\",\n       subtitle = \"2001 to 2010\")+\n  theme_minimal() +\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\")+\n  scale_color_manual(values = c(\"darkgreen\", \"red\", \"#999999\"),\n                    labels = c(\"Coho\", \"Jack Coho\", \"Steelhead\"))+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\nIsolate from 2009 to 2011 and make an additional plot for clarity.\n\n\n\nCode\nsalmon_ts_filter &lt;- salmon_ts_pivot %&gt;% \n  filter_index(\"2009-01-01\" ~ \".\")\n\nzoom_plot_ts &lt;- ggplot(data = salmon_ts_filter, aes(x = date, y = count, color = species)) +\n  geom_line() + \n  labs(x = \" \",\n       y = 'Abundance',\n       color = \"Species\",\n       subtitle = \"2009 to 2010\")+\n  theme_minimal() +\n  scale_x_date(date_breaks = \"2 month\", date_labels = \"%b\")+\n  scale_color_manual(values = c(\"darkgreen\", \"red\", \"#999999\"),\n                    labels = c(\"Coho\", \"Jack Coho\", \"Steelhead\"))+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\nPut the plots together in one figure.\n\n\n\nCode\nfigure_1 &lt;- plot_ts / zoom_plot_ts\nfigure_1 + plot_annotation(tag_levels = \"A\")\n\n\n\n\n\nFigure 1: Salmon Abundance in Willamette Falls fish passage from 2001 to 2010. Plot A portrays salmon abundance across all the years. There are clear oscillations and seasonality across all three species (Coho, Jack-coho, and Steelhead salmon). Plot B highlights a subset of the data, focusing on salmon abundance from 2009 to 2010 to better portray the seasonality across the three species for a given year. The coho and jack-coho salmon abundances peak in the fall months (Sept - Nov) and the steelhead abundance peaks in the summer (May - July)."
  },
  {
    "objectID": "posts/2024-02-02-time-series/index.html#part-2-seasonplot",
    "href": "posts/2024-02-02-time-series/index.html#part-2-seasonplot",
    "title": "Time Series Analysis",
    "section": "Part 2: Seasonplot",
    "text": "Part 2: Seasonplot\nAs shown in Figure 2, the coho salmon abundance peaks in the fall months from Sept. to Nov. There is a clear increase in the species population size from 2001 to 2010. Likewise, the jack-coho abundance spikes in the fall months and also has an increase in species abundance over the ten years span. In comparison, Steelhead salmon abundance more steadily rises from January through July. There numbers appear to be declining over the years.\n\nSteps\n\nMake a seasonplot"
  },
  {
    "objectID": "posts/2024-02-02-time-series/index.html#part-3-annual-counts-by-species",
    "href": "posts/2024-02-02-time-series/index.html#part-3-annual-counts-by-species",
    "title": "Time Series Analysis",
    "section": "Part 3: Annual counts by species",
    "text": "Part 3: Annual counts by species\nAs shown in Figure 3, there are clear trends in annual salmon counts for each species from 2001 to 2010. The Steelhead salmon have the greatest abundance out of the three species and have an overall declining trend with a increase from 2009 to 2010. Coho salmon remain consistent from 2001 to 2008 and then have a large increase in their abundance. And Jack coho salmon have the lowest species abundance across the years and remain at a constant size.”\n\nSteps\n\nGroup by year and species to find total abundances.\n\n\n\nCode\nfish_year &lt;- salmon_ts_pivot %&gt;%\n  index_by(year = ~year (.)) %&gt;%\n  group_by(year, species) %&gt;%\n  summarise(count = sum(count, na.rm = TRUE)) %&gt;%\n  ungroup\n\n\n\nMake a pretty plot.\n\n\n\nCode\nyear_plot2 &lt;- ggplot(data = fish_year, aes(x = year, y = count, color = species)) + \n  geom_line() +\n  scale_color_manual(values = c(\"darkgreen\", \"red\", \"#999999\"),\n                    labels = c(\"Coho\", \"Jack Coho\", \"Steelhead\")) +\n  labs(x = '',\n       y = 'Abundance', \n       color = \"Species\")+ \n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))+\n  scale_x_continuous(breaks = fish_year$year)\nyear_plot2\n\n\n\n\n\nFigure 3: Salmon Abundance per Year from 2001 to 2010. The figure portray the trends in annual salmon abundance totals for the three species. The Steelhead salmon have the greatest abundance out of the three species and have an overall declining trend with a increase from 2009 to 2010. Coho salmon remain consistent from 2001 to 2008 and then have a large increase in their abundance. And Jack coho have the lowest species abundance across the years and remain at a constant size."
  },
  {
    "objectID": "posts/2024-02-02-time-series/index.html#works-cited",
    "href": "posts/2024-02-02-time-series/index.html#works-cited",
    "title": "Time Series Analysis",
    "section": "Works Cited",
    "text": "Works Cited\nU.S. Army Corps of Engineers, NWD; Chelan, Douglas, and Grant County PUDs; Yakima Klickitat Fisheries Project; Colville Tribes Fish & Wildlife (OBMEP); Oregon Department of Fish & Wildlife; Washington Department of Fish & Wildlife. DART Adult Passage Counts Graphics & Text. Columbia Basin Research, Univeristy of Washington. Accessed on January 25, 2024. https://www.cbr.washington.edu/dart/query/adult_graph_text"
  },
  {
    "objectID": "posts/2024-12-17-benefits-transfer/index.html",
    "href": "posts/2024-12-17-benefits-transfer/index.html",
    "title": "Benefits Transfer",
    "section": "",
    "text": "Huntington Beach wetlands, Photo Credit: Huntington Beach Wetlands Conservancy\n\n\n\nBackground\nCoastal wetlands provide a natural defense against storm surges and the effects of sea-level rise. They act like a sponge that dissipates wave impacts and reduces flood risk. Benefit transfer analysis can be used to determine the value of a 60 hectare salt marsh wetlands in Huntington Beach, California.\n\n\nData\nThe analysis will pull from these two studies:\n\nBayraktov et al. (2015): a meta-analysis of coastal wetland restoration costs. Specifically, you have access to the mangrove and salt marsh databases.\nCostanza et al. (2021): estimate the storm protection benefits (avoided damage).\n\nThe dataset of Bayraktov et al. (2015) and has the following information:\n1) study_cluster: research belonging to a specific year\n2) wetland_type: mangrove or saltmarsh\n3) observation: research ID\n4) reference: authors\n5) ref_year: publication year\n6) country: country where the restoration project took place\n7) area_ha: restoration area\n8) total_cost_2010: total restoration cost in USD2010\n\n\nRestoration costs\nEmploy a benefit transfer to find the costs of restoring 60 hectares of wetland.\n\nInspect the dataset. What wetland type is most appropriate for your analysis? Filter the dataset for that wetland type.\n\nWe want saltmarsh wetlands for our analysis.\n\nCreate a new variable with the restoration costs per hectare. Then, choose one of the research studies and estimate the total costs of restoring 60 hectares in Huntington Beach. Explain your choice.\n\nTo choose a research study, I filtered for projects in the USA with an area greater than or equal to 60 hectares. From these four results, I consulted with the larger data set from the Bayraktov et al. (2015) study to determine that observation #106 was a project in the San Francisco Bay area of California. Because our restoration site is in Huntington Beach, California, I chose observation #106 as the most appropriate for our analysis based on geographic location. Based on the restoration cost per hectare for observation #106, the total cost of restoring 60 hectares in Huntington Beach is $5,496,801.63\n\n\nCode\n#load libraries\nlibrary(tidyverse)\nlibrary(here)\n\nrm(list = ls())\n\n# Load the data\ncost_df &lt;- read_csv(here(\"posts/2024-12-17-benefits-transfer/cost_df.csv\"))\n\n# Filter for saltmarsh\nsaltmarsh_df &lt;- cost_df %&gt;%\n  filter(wetland_type == \"saltmarsh\") %&gt;% \n  drop_na()\n\n# Create a new variable with the restoration costs per hectare\nsaltmarsh_df &lt;- saltmarsh_df %&gt;%\n  mutate(cost_per_ha = total_cost_2010 / area_ha)\n\n# Choose one of the research studies\nsaltmarsh_df %&gt;% \n  filter(country == \"USA\") %&gt;%\n  filter(area_ha &gt;= 60) \n\n\n# A tibble: 4 × 9\n  study_cluster wetland_type observation reference      ref_year country area_ha\n          &lt;dbl&gt; &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n1             1 saltmarsh              2 Adams CS, Ben…     1998 USA        160 \n2            18 saltmarsh             75 Milano G           1999 USA        122.\n3            26 saltmarsh            103 Society for E…     2007 USA        197.\n4            29 saltmarsh            106 Society for E…     2008 USA        130.\n# ℹ 2 more variables: total_cost_2010 &lt;dbl&gt;, cost_per_ha &lt;dbl&gt;\n\n\nCode\n# estimate the total costs of restoring 60 hectares in Huntington Beach based on observation #106\ntotal_cost_60_ha &lt;- saltmarsh_df %&gt;%\n  filter(observation == 106) %&gt;%\n  pull(cost_per_ha) * 60\ntotal_cost_60_ha\n\n\n[1] 5496802\n\n\n\nWe are interested in the marginal cost of each additional hectare restored. Make a scatter plot of hectares on the y-axis and total restoration costs on the x-axis in the USA. Describe the relationship between total costs and wetland area restored.\n\n\n\nCode\n#filter for only USA\nsaltmarsh_usa &lt;- saltmarsh_df %&gt;% \n  filter(country==\"USA\")\n\n# Scatter plot of hectares on the y-axis and total restoration costs on the x-axis in the USA\nsaltmarsh_usa %&gt;%\n  ggplot(aes(x = total_cost_2010, y = area_ha)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  scale_x_log10() +  # Log transform x-axis\n  scale_y_log10() +  # Log transform y-axis \n  labs(title = \"Total Restoration Costs by Area of Restored Saltmarsh\",\n       x = \"Total Restoration Costs (USD2010, log scale)\",\n       y = \"Wetland Area Restored (ha, log scale)\") + \n  theme_minimal()\n\n\n\n\n\nScatter plot of total restoration costs and hectares of saltmarsh wetland restored in the USA\n\n\n\n\nThe scatter plot shows a positive relationship between total restoration costs and hectares of wetland area restored. As the area of wetland restoration increases, the total restoration costs also increases. The relationship appears to be linear, with a few outliers that have higher restoration costs for a given area of wetland restoration.\n\nRun the following regression: total_cost_2010 = a + b*area_ha + error. Using the outcome of this regression, recalculate the total cost of restoring 60 hectares of wetland.\n\n\n\nCode\n# Run the regression\nlm_cost &lt;- lm(total_cost_2010 ~ area_ha, data = saltmarsh_usa)\nsummary(lm_cost)\n\n\n\nCall:\nlm(formula = total_cost_2010 ~ area_ha, data = saltmarsh_usa)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-5239511  -541661  -352808    87971  7111292 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   446092     368986   1.209    0.234    \narea_ha        43861       7093   6.183 3.55e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2011000 on 37 degrees of freedom\nMultiple R-squared:  0.5082,    Adjusted R-squared:  0.4949 \nF-statistic: 38.23 on 1 and 37 DF,  p-value: 3.546e-07\n\n\nCode\n# Recalculate the total cost of restoring 60 hectares of wetland\ntotal_cost_60_ha_lm &lt;- coef(lm_cost)[1] + coef(lm_cost)[2] * 60\ntotal_cost_60_ha_lm\n\n\n(Intercept) \n    3077755 \n\n\nThe total cost from the regression is $3,077,755 to restore 60 hectares of wetland in Huntington Beach. This estimate is much lower than the previous estimate based on observation #106.\n\nDescribe one way you could improve your cost analysis and valuation.\n\nOne way to improve the cost analysis and valuation is to include additional variables that may influence the restoration costs. For example, factors such as the type of restoration activities, the condition of the wetland site, and the availability of resources could impact the total restoration costs. By including these variables in the analysis, we can better estimate the costs of restoring wetlands and provide more accurate benefit transfer estimates.\n\n\nStorm protection benefits\nCostanza et al. (2021) analyzed 1288 coastal storms globally to calculate the storm protection benefits from wetlands. The authors obtained the following regression estimates:\n\\(ln(damages/GDP) = -7.992 - 0.236ln(wetlands) + 3.298ln(windspeed) - 0.55ln(speed) + 0.137(volume) - 0.058(time)\\)\nThey have the following variables:\n\ndamages/GDP,\nwind speed of the storm (windspeed),\nthe forward speed of the storm (speed),\nwetland area in the swath of the storm (wetlands),\nthe volume of water in the ocean proximal to the storm landfall (volume),\nand the year of the storm minus 1900 (time) as a (non-transformed) linear variable.\n\n\nInterpret the coefficient on ln(wetlands). (Hint: notice that the dependent variable is also log-transformed)\n\nThe coefficient on ln(wetlands) is -0.236. This coefficient indicates that a 1% increase in wetland area in the swath of the storm is associated with a 0.236% decrease in damages relative to GDP. Because both the dependent variable (damages/GDP) and the wetland area are log-transformed, this coefficient captures the percentage change in damages/GDP resulting from a 1% change in wetland area. In other words, a larger wetland area provides greater storm protection benefits by reducing the damages caused by coastal storms.\n\nCalculate the avoided damage of 60 additional hectares of wetlands in case of a storm like Hurricane Hilary. You have the following information: damages = $18 million, and the available wetland area today is 72 hectares. Assume the GDP doesn’t change (only damage moves), and all the remaining variables remain constant.\n\n\n\nCode\n#calculate change in wetland \ncurrent_wetland_area &lt;- 72\nadditional_wetland_area &lt;- 60\ntotal_wetland_area &lt;- current_wetland_area + additional_wetland_area \n# 72 + 60 = 132\n\n\nln_wetland &lt;- log(total_wetland_area/current_wetland_area)\n# ln_wetland\n#log(132/72) = 0.6061358034\n\n#reduction in damages\nln_damages &lt;- -0.236 * ln_wetland\n# - 0.236 * 0.6061358034 = -0.1430480496\n# ln_damages\n\n#calculate damage\ndamages &lt;- 18000000  \ndamage_new &lt;- damages * exp(ln_damages)\n#18,000,000 * exp(-0.1430480496)\n# damage_new\n\navoided_damage = damages - damage_new\n#18000000 - 15600824 = 2399176\navoided_damage \n\n\n[1] 2399176\n\n\nThe avoided damage from 60 additional hectares of wetlands in case of a storm like Hurricane Hilary is $2,399,176.\n\n\n\n\nCitationBibTeX citation:@online{calbert2024,\n  author = {Calbert, Madison},\n  title = {Benefits {Transfer}},\n  date = {2024-12-17},\n  url = {https://madicalbert.github.io/posts/2022-12-17-benefits-transfer/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nCalbert, Madison. 2024. “Benefits Transfer.” December 17,\n2024. https://madicalbert.github.io/posts/2022-12-17-benefits-transfer/."
  },
  {
    "objectID": "posts/2024-02-10-spatial-data/index.html",
    "href": "posts/2024-02-10-spatial-data/index.html",
    "title": "Spatial Data Analysis",
    "section": "",
    "text": "Oil on the beach at Refugio State Park in Santa Barbara, California, on May 19, 2015. (U.S. Coast Guard)."
  },
  {
    "objectID": "posts/2024-02-10-spatial-data/index.html#overview",
    "href": "posts/2024-02-10-spatial-data/index.html#overview",
    "title": "Spatial Data Analysis",
    "section": "Overview",
    "text": "Overview\nIn this report, I explore oil spill incidents throughout all 58 California counties in the year 2008. I used data from CA Department of Fish and Wildlife (CDFW) Oil Spill Incident Tracking [ds394] that was published on July 29, 2009. “The Office of Spill Prevention and Response (OSPR) Incident Tracking Database is a statewide oil spill tracking information system. The data are collected by OSPR Field Response Team members for Marine oil spills and by OSPR Inland Pollution Coordinators and Wardens for Inland incidents. An ‘incident’, for purposes of this database, is a discharge or threatened discharge of petroleum or other deleterious material into the waters of the state.” The purpose of this analysis is to develop a better understanding of which California counties have the most oil spill incidents and to spatially visualize the oil spill incidents."
  },
  {
    "objectID": "posts/2024-02-10-spatial-data/index.html#spatial-data-visualization",
    "href": "posts/2024-02-10-spatial-data/index.html#spatial-data-visualization",
    "title": "Spatial Data Analysis",
    "section": "Spatial Data Visualization",
    "text": "Spatial Data Visualization\nCreate an interactive map displaying all oil spill incidents in each CA county:\n\nLoad all Libraries needed for this analysis.\nLoad the California county data shape files and the oil spill data sets.\nConvert the oil spill data set into a shape file and ensure it has the same coordinate reference system (CRS) as the California counties shape file.\nPerform a spatial join of CA counties over oil spill points.\nMake an interactive map of oil spill incidents by county.\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(here)\nlibrary(sf) \nlibrary(terra) \nlibrary(tidyterra) \nlibrary(gstat)\nlibrary(stars)\nlibrary(janitor)\nlibrary(tmap)\nlibrary(spatstat)\n\n\n\n\nCode\n### spatial join \n\noil_ca_sf &lt;- st_join(oil_sf, ca_counties_sf) ### points over counties\nca_oil_sf &lt;- st_join(ca_counties_sf, oil_sf) ### counties over points"
  },
  {
    "objectID": "posts/2024-02-10-spatial-data/index.html#chloropleth-map",
    "href": "posts/2024-02-10-spatial-data/index.html#chloropleth-map",
    "title": "Spatial Data Analysis",
    "section": "Chloropleth Map",
    "text": "Chloropleth Map\nDetermine the number of oil spill incidents in each county to display the counties with the greatest amount of oil spill occurrences:\n\nGroup the oil spill data by county and summarize the number of oil spills in each county.\nCreate the chloropleth map.\n\n\n\nCode\n### group by county and summarize \n\noil_counts_sf &lt;- ca_oil_sf %&gt;% \n  mutate(county = name) %&gt;% \n  group_by(county) %&gt;%\n  summarize(oil_counts = n())\n\n\n\n\nCode\n### chloropleth map \n\nggplot(data = oil_counts_sf) +\n  geom_sf(aes(fill = oil_counts), color = \"white\", size = 0.1) +\n  scale_fill_gradientn(colors = c(\"lightgray\",\"orange\",\"red\")) +\n  theme_minimal() +\n  labs(fill = \"Number of oil spill incidents\")\n\n\n\n\n\nFigure 2: Abundance of Oil Spill Incidents in 2008 in CA. This figure displays that the greatest number of oil spill incidents are occuring in Los Angeles and San Diego counties."
  },
  {
    "objectID": "posts/2024-02-10-spatial-data/index.html#point-pattern-analysis",
    "href": "posts/2024-02-10-spatial-data/index.html#point-pattern-analysis",
    "title": "Spatial Data Analysis",
    "section": "Point Pattern Analysis",
    "text": "Point Pattern Analysis\nPerform a point pattern analysis to assess whether oil spills tend to be more clustered or more uniform than complete spatial randomness:\n\nConvert oil observations to spatial point pattern\nConvert county boundaries to observation window\nCombine as a point pattern object (points + window)\nPlot it\n\n\n\nCode\n### Convert oil observations to spatial point pattern\noil_ppp &lt;- as.ppp(oil_sf) \n\n### Convert county boundary to observation window\nca_counties_win &lt;- as.owin(ca_counties_sf) \n\n### Combine as a point pattern object (points + window):\noil_full &lt;- ppp(oil_ppp$x, oil_ppp$y, window = ca_counties_win)\n\nplot(oil_full, main = \"Oil Spill Incidents from 2008\") \n\n\n\n\n\nFigure 3: Point Pattern Analysis of Oil Spills in CA from 2008. This figure portrays that San Francisco, Los Angeles, and San Diego counties have the highest occurences of oil spills and clustering. The plus sign denotes illegal point or oils spills that fall outside the window.\n\n\n\n\nPlot the G function to determine clustering:\n\nMake a sequence of distances over which you’ll calculate G(r)\nCalculate the actual and theoretical G(r) values, using 100 simulations of CSR for the “theoretical” outcome\nCheck the output of gfunction, then gather this to plot series in ggplot, then make a graph in ggplot\n\n\n\nCode\n### Make a sequence of distances over which you'll calculate G(r)\nr_vec &lt;- seq(0, 10000, by = 100) \n\ngfunction_out &lt;- envelope(oil_full, fun = Gest, r = r_vec, \n                          nsim = 100, verbose = FALSE) \n### Calculate the actual and theoretical G(r) values, using 100 \n### simulations of CSR for the \"theoretical\" outcome\n\ngfunction_out ### Check the output of gfunction, then...\n\n\nPointwise critical envelopes for G(r)\nand observed value for 'oil_full'\nEdge correction: \"km\"\nObtained from 100 simulations of CSR\nAlternative: two.sided\nSignificance level of pointwise Monte Carlo test: 2/101 = 0.0198\n.....................................................................\n     Math.label     Description                                      \nr    r              distance argument r                              \nobs  hat(G)[obs](r) observed value of G(r) for data pattern          \ntheo G[theo](r)     theoretical value of G(r) for CSR                \nlo   hat(G)[lo](r)  lower pointwise envelope of G(r) from simulations\nhi   hat(G)[hi](r)  upper pointwise envelope of G(r) from simulations\n.....................................................................\nDefault plot formula:  .~r\nwhere \".\" stands for 'obs', 'theo', 'hi', 'lo'\nColumns 'lo' and 'hi' will be plotted as shading (by default)\nRecommended range of argument r: [0, 6100]\nAvailable range of argument r: [0, 10000]\n\n\nCode\n### Gather this to plot series in ggplot:\ngfunction_long &lt;- gfunction_out %&gt;% \n  as.data.frame() %&gt;% \n  pivot_longer(cols = obs:hi, names_to = \"model\", values_to = \"g_val\")\n\n### Then make a graph in ggplot:\nggplot(data = gfunction_long, aes(x = r, y = g_val, group = model)) +\n  geom_line(aes(color = model)) +\n  theme_minimal() +\n  labs(x = 'radius (m)', y = 'G(r)')\n\n\n\n\n\nFigure 4: G Function Analysis of Oil Spills in CA. This figure conveys that our observations are very clustered because the observation line is above the theoretical line.\n\n\n\n\nCode\n### our observations are very clustered because it is above the theoretical line (CSR line in leture notes)\n\n\n\n\n\nA Snowy Plover is rehabilitated after being exposed to oil. Photo: Oiled Wildlife Care Network."
  },
  {
    "objectID": "posts/2024-02-10-spatial-data/index.html#works-cited",
    "href": "posts/2024-02-10-spatial-data/index.html#works-cited",
    "title": "Spatial Data Analysis",
    "section": "Works Cited",
    "text": "Works Cited\nOil Spill Incident Tracking [ds394]. California Department of Fish and Wildlife. Published July 29, 2009. Retrieved from: https://gis.data.ca.gov/datasets/CDFW::oil-spill-incident-tracking-ds394-1/about"
  },
  {
    "objectID": "posts/2024-09-20-habitat-suitability/index.html",
    "href": "posts/2024-09-20-habitat-suitability/index.html",
    "title": "Habitat Suitability",
    "section": "",
    "text": "African Lions, Photo Credit: African Lion and Environmental Research Trust\n\n\nBackground: African lions (Panthero leo) are critically endangered and are under threat from climate change. As environmental conditions change, their habitat distributions will also shift. We modeled and mapped present and future distributions of the African lion using the Wallace package in R and in ArcGIS to understand future habitat suitability.\nProblem: Habitat suitability modeling under different climate scenarios will allow wildlife managers to better understand where to create protected reserves to maximize habitat suitability for lions in the future. This analysis provides priority areas for suitable lion habitat under the SSP370 climate scenario.\nApproach: In Wallace, we determined African lion habitat suitability change based on lion occurrence data and environmental data that consisted of bioclimatic variables including:\n\nBIO1 = Annual Mean Temperature\nBIO2 = Mean Diurnal Range (Mean of monthly (max temp - min temp))\nBIO5 = Max Temperature of Warmest Month\nBIO6 = Min Temperature of Coldest Month\nBIO12 = Annual Precipitation\nBIO13 = Precipitation of Wettest Month\nBIO17 = Precipitation of Driest Quarter\n\nWe sampled 1000 background points using the environmental data to capture any environmental conditions that may have been missed in the occurrence sample data. Next, we validated the model with a training and testing data set to test the model using spatial partitioning, choosing the “block” method.\nWe used the Maxent module to ensure both lion occurrence and background data were used and selected the maxnet algorithm. We used a linear (LQ) feature class of our bioclim variables (temperature and precipitation). Additionally, we checked LQHP features and ran the model again. When comparing the response curves between the LQ and LQHP models, the LQHP model was not biologically plausible for the lion. The LQHP response curves showed no clear relationship between the modeled suitability and each predictor variable, indicating that this model was overfit. Therefore, we proceeded with the LQ feature class.\nNext, we explored the impacts of climate change on our lion occurrence model. In the Maxent module, we used Model Transfer to create a modeled lion distribution map under the SSP370 climate scenario. This scenario is in the upper-middle part of the full range of scenarios, with an additional radiative forcing of 7 W/m² by the year 2100. We used the latest available data in Wallace and chose the climate model MIROC6 and climate scenario SSP370. Additionally, we explored climate scenario SSP126, with an additional radiative forcing of 2.6 W/m² by the year 2100, and which simulates development that is compatible with a 2°C target. Finding little difference between the two climate scenarios, we proceeded with SSP370. Next, we exported the files from Wallace and pulled the output into ArcGIS Pro. Then, we updated the symbology to be consistent with a specific style layer to visualize the changes in range distribution between present and future scenarios. Lastly, we used Raster math to calculate the change in habitat suitability between the SSP370 model and our original lion distribution model.\nResults: Our results showed a change in habitat suitability for the African Lion under climate model SSP370. As shown in Figure 1, the largest area of positive change in habitat suitability is shifting poleward, as noted by the bright red in the map. Yellow indicates no change in suitability, however, blue indicates a negative change in suitability as shown in the middle and upper regions of the area.\nConclusions: Conservation actions for African lions should prioritize potential range shifts from climate change. As shown in our results, suitable habitat shifts poleward and wildlife managers should ensure that there are sufficient protected areas for lions under these future climate scenarios. This range shift could cause increased human wildlife conflict between lions and private landowners who inhabit these areas.\n\n\n\nFigure 1. Habitat Suitability Change in African Lions. Change in habitat suitability between SSP370 and future distribution using raster analysis. The map shows a poleward shift in range: yellow indicates no change in suitability, blue denotes a negative change in suitable habitat, and red represents a positive change in habitat suitability.\n\n\n\n\n\nCitationBibTeX citation:@online{calbert_and_natalie_smith2024,\n  author = {Calbert and Natalie Smith, Madison},\n  title = {Habitat {Suitability}},\n  date = {2024-09-20},\n  url = {https://madicalbert.github.io/posts/2024-09-20-habitat-suitability/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nCalbert and Natalie Smith, Madison. 2024. “Habitat\nSuitability.” September 20, 2024. https://madicalbert.github.io/posts/2024-09-20-habitat-suitability/."
  },
  {
    "objectID": "posts/2024-03-03-binary-log-regression/index.html",
    "href": "posts/2024-03-03-binary-log-regression/index.html",
    "title": "Binary Logistic Regression",
    "section": "",
    "text": "Serenoa repens is a flowering, perennial, wetland shrub that is commonly found in wet to dry flatwoods and hammocks throughout the state of Florida."
  },
  {
    "objectID": "posts/2024-03-03-binary-log-regression/index.html#overview",
    "href": "posts/2024-03-03-binary-log-regression/index.html#overview",
    "title": "Binary Logistic Regression",
    "section": "Overview",
    "text": "Overview\nSaw Palmetto (Serenoa repens) and Scrub Palmetto (Sabal etonia) are both species of palms native to Florida. In this report, I use binary logistic regression to test the feasibility of using different plant characteristics to differentiate between the two species. The different plant variables include plant height (height), canopy length (length), canopy width (width), and number of green leaves (green_lvs)."
  },
  {
    "objectID": "posts/2024-03-03-binary-log-regression/index.html#data-source",
    "href": "posts/2024-03-03-binary-log-regression/index.html#data-source",
    "title": "Binary Logistic Regression",
    "section": "Data Source",
    "text": "Data Source\nThe data for this analysis was sourced from Environmental Data Initiative Data Portal. This data package is comprised of three datasets all pertaining to two dominant palmetto species, Serenoa repens and Sabal etonia, at Archbold Biological Station in south-central Florida.\nData source: Abrahamson, W.G. 2019. Survival, growth and biomass estimates of two dominant palmetto species of south-central Florida from 1981 - 2017, ongoing at 5-year intervals ver 1. Environmental Data Initiative. https://doi.org/10.6073/pasta/f2f96ec76fbbd4b9db431c79a770c4d5"
  },
  {
    "objectID": "posts/2024-03-03-binary-log-regression/index.html#pseudocode",
    "href": "posts/2024-03-03-binary-log-regression/index.html#pseudocode",
    "title": "Binary Logistic Regression",
    "section": "Pseudocode",
    "text": "Pseudocode\n\nLoad libraries, load data, clean/tidy the data, select desired variables (species, height, length, width, green_lvs)\nData visualization to hypothesize which variables differ between species.\nBuild the two models: Model 1 determines species based on height, length, width, and number of leaves; & Model 2 determines species based on height, width, and number of leaves (excluding length).\nRun the binary logistic regression on both models, using generalized linear model.\nSplit the data into testing group and training group.\nInitialize workflow\nApply workflow to folded training data set for both models.\nTrain the whole data set with the best model to determine which variables best predict species.\n\n\n\nCode\n### Load libraries\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(tidymodels)\n\nlibrary(cowplot)\nlibrary(kableExtra)\nlibrary(broom)\n\n\n### Load in the data\n\np_df &lt;- read_csv(here('posts', '2024-03-03-binary-log-regression','data', 'palmetto.csv'))\n\n\n### Tidy the data and make species a factor\n\np_clean &lt;- p_df %&gt;% \n  select(species, height, length, width, green_lvs) %&gt;% \n  mutate(species = as_factor(species)) %&gt;% \n  drop_na()"
  },
  {
    "objectID": "posts/2024-03-03-binary-log-regression/index.html#methods",
    "href": "posts/2024-03-03-binary-log-regression/index.html#methods",
    "title": "Binary Logistic Regression",
    "section": "Methods",
    "text": "Methods\n\nData Visualization\n\n\nCode\nlvs_bp &lt;- ggplot(p_clean, aes(x = as_factor(species), y = green_lvs)) + \n  geom_boxplot(fill = \"lightgreen\") + \n  labs(x = \" \", \n       y = \"Number of Leaves\") +\n  theme_minimal()+\n  scale_x_discrete(labels = c(\"S. repens\", \"S. etonia\"))\n\nheight_bp &lt;- ggplot(p_clean, aes(x = as_factor(species), y = height)) + \n  geom_boxplot(fill = \"lightgreen\")+ \n  labs(x = \" \", \n       y = \"Height (cm)\") +\n  theme_minimal()+\n  scale_x_discrete(labels = c(\"S. repens\", \"S. etonia\"))\n\nlength_bp &lt;- ggplot(p_clean, aes(x = as_factor(species), y = length)) + \n  geom_boxplot(fill = \"lightgreen\")+ \n  labs(x = \" \", \n       y = \"Canopy Length (cm)\") +\n  theme_minimal()+\n  scale_x_discrete(labels = c(\"S. repens\", \"S. etonia\"))\n\nwidth_bp &lt;- ggplot(p_clean, aes(x = as_factor(species), y = width)) + \n  geom_boxplot(fill = \"lightgreen\")+ \n  labs(x = \" \", \n       y = \"Canopy Width (cm)\") +\n  theme_minimal()+\n  scale_x_discrete(labels = c(\"S. repens\", \"S. etonia\"))\n\n### put it all together now \n\ncombined_plot &lt;- plot_grid(\n  lvs_bp, height_bp,\n  length_bp, width_bp,\n  ncol = 2  \n)\n\nprint(combined_plot)\n\n\n\n\n\nFigure 1: Saw Palmetto (Serenoa repens) and Scrub Palmetto (Sabal etonia) differ by the number of leaves and are fairly similar based on height, canopy width, and canopy length. Number of leaves appears to be the best predictor variable to differentiate these two palmetto species.\n\n\n\n\n\n\nDefine the models\n\nModel 1: Species as a function of height, canopy length, canopy width, and number of leaves\nModel 2: Species as a function of height, canopy width, and number of leaves\n\n\n\nCode\n### sps. 1 = s. repens\n### sps. 2 = s. etonia\n\nf1 &lt;- species ~ height + length + width + green_lvs \nf2 &lt;- species ~ height + width + green_lvs\n\n\n\n\nCrossfold Validation\nModel 1 has an accuracy of 92%, this is the percent classified correctly in the testing group. In addition, the ROC is 97% which is good and explains that we do not have a lot of false positives. We are close to a perfect classifier.\n\n\nCode\np_clean %&gt;%\n  group_by(species) %&gt;%\n  summarize(n = n()) %&gt;%\n  ungroup() %&gt;%\n  mutate(prop = n / sum(n))\n\nset.seed(10101)\np_folds &lt;- vfold_cv(p_clean, v = 10, repeats = 10)\n\n\nblr_mdl &lt;- logistic_reg() %&gt;%\n  set_engine('glm') ### this is the default - we could try engines from other packages or functions\n\n\nblr_wf &lt;- workflow() %&gt;%   ### initialize workflow\n  add_model(blr_mdl) %&gt;%\n  add_formula(formula = f1)\n\n\nblr_fit_folds &lt;- blr_wf %&gt;%\n  fit_resamples(p_folds)\n\n\n### Average the predictive performance of the ten models:\n# collect_metrics(blr_fit_folds)\n\n\nModel 2 has an accuracy of 89%, so this model is not as accurate of a predictor compares to Model 1. In addition the ROC is 96% which is still a good value, but not as strong as Model 1.\n\n\nCode\nblr2_wf &lt;- workflow() %&gt;%   ### initialize workflow\n  add_model(blr_mdl) %&gt;%\n  add_formula(formula = f2)\n\n\nblr2_fit_folds &lt;- blr2_wf %&gt;%\n  fit_resamples(p_folds)\n\n\n### Average the predictive performance of the ten models:\n# collect_metrics(blr2_fit_folds)\n\n\n\n\nCheck AIC\nModel 1 has a lower AIC compared to Model 2, so Model 1 is a better predictor of species.\n\n\nCode\nblr1_fit &lt;- blr_mdl %&gt;%\n  fit(formula = f1, data = p_clean)\n\nblr2_fit &lt;- blr_mdl %&gt;%\n  fit(formula = f2, data = p_clean)\n\n# blr1_fit\n### AIC of 5195\n\n# blr2_fit\n### AIC of 5987"
  },
  {
    "objectID": "posts/2024-03-03-binary-log-regression/index.html#results",
    "href": "posts/2024-03-03-binary-log-regression/index.html#results",
    "title": "Binary Logistic Regression",
    "section": "Results",
    "text": "Results\n\nBinary Logistic Regression\nModel 1 is a better predictor of species because it has a lower AIC (5195), a higher accuracy (92%) and a higher ROC (97%) compared to Model 2.\nFor Model 1, all variables are statistically significant at predicting species. For every unit increase in plant height, the log odds outcome will decrease by 0.029. Number of leaves has the greatest effect on the log odds of plant type. Results from the BLR are showcased in Table 1.\n\n\nCode\nblr1 &lt;- glm(formula = f1, data = p_clean, family = binomial)\nsummary(blr1)\n# all p-values are small, so all coefficients are significant \n# for every unit increase in height the log odds outcome decreases by 0.0029\n\nblr1_fit &lt;- blr_mdl %&gt;%\n  fit(formula = f1, data = p_clean)\n\n\np_predict &lt;- p_clean %&gt;%\n  mutate(predict(blr1_fit, new_data = .))\n\n\n\n\nCode\n# summary(blr1)\ntidy &lt;- broom::tidy(blr1)\n\nnew_column_names &lt;- c(\"Coefficient\", \"Estimate\", \"Standard Error\", \"Statistic\", \"P-Value\")\ncolnames(tidy) &lt;- new_column_names\n\ntidy_table &lt;- kable(tidy, align = \"c\") %&gt;%\n  kable_styling(full_width = FALSE)\n\ntidy_table\n\n\n\n\n\n\nCoefficient\n\n\nEstimate\n\n\nStandard Error\n\n\nStatistic\n\n\nP-Value\n\n\n\n\n\n\n(Intercept)\n\n\n3.2266851\n\n\n0.1420708\n\n\n22.71180\n\n\n0\n\n\n\n\nheight\n\n\n-0.0292173\n\n\n0.0023061\n\n\n-12.66984\n\n\n0\n\n\n\n\nlength\n\n\n0.0458233\n\n\n0.0018661\n\n\n24.55600\n\n\n0\n\n\n\n\nwidth\n\n\n0.0394434\n\n\n0.0021000\n\n\n18.78227\n\n\n0\n\n\n\n\ngreen_lvs\n\n\n-1.9084747\n\n\n0.0388634\n\n\n-49.10728\n\n\n0\n\n\n\n\nTable 1: Results from Model 1 binary logistic regression looking at plant height, length, width, and number of leaves. Includes coefficients, estiamte, standard errors for the coefficients, statistics, and p-value.\n\n\n\n\nPredictions\nFor each species of palmetto, Table 2 shows how many plants in the original dataset would be correctly classified and how many were incorrectly classified by Model 1, as well as an the “% correctly classified”.\n\n\nCode\n### MODEL 1\nsps_test1_predict &lt;- p_clean %&gt;%\n  ### straight up prediction, based on 50% prob threshold (to .pred_class):\n  mutate(predict(blr1_fit, new_data = p_clean)) %&gt;%\n  ### but can also get the raw probabilities of class A vs B (.pred_A, .pred_B):\n  mutate(predict(blr1_fit, new_data = ., type = 'prob'))\n    ### note use of `.` as shortcut for \"the current dataframe\"\n\n\ntable(sps_test1_predict %&gt;%\n        select(species, .pred_class))\n\naccuracy(sps_test1_predict, truth = species, estimate = .pred_class)\n\n\n\n\nCode\nspecies &lt;- c(\"S. repens\", \"S. etonia\")\npredict_correct &lt;- c(5548, 5701)\npredict_incorrect &lt;- c(564, 454)\npercent_correct &lt;- c(91, 93)\n\nspecies_correct &lt;- data.frame(species, predict_correct, predict_incorrect, percent_correct)\n\ncolumn_names &lt;- c(\"Species\", \"# Correctly Predicted\", \"# Incorrectly Predicted\", \"Percent Correct\")\ncolnames(species_correct) &lt;- column_names\n\nspecies_correct_kable &lt;- kable(species_correct, align = \"c\") %&gt;% \n  kable_styling()\n\nspecies_correct_kable\n\n\n\n\n\n\nSpecies\n\n\n# Correctly Predicted\n\n\n# Incorrectly Predicted\n\n\nPercent Correct\n\n\n\n\n\n\nS. repens\n\n\n5548\n\n\n564\n\n\n91\n\n\n\n\nS. etonia\n\n\n5701\n\n\n454\n\n\n93\n\n\n\n\nTable 2: Shows how successfully Model 1 can “classify” a plant as the correct species. Shows how many plants in the original dataset would be correctly classified and how many were incorrectly classified by the model, also shows the percent correctly classified."
  },
  {
    "objectID": "posts/2024-03-03-binary-log-regression/index.html#conclusions",
    "href": "posts/2024-03-03-binary-log-regression/index.html#conclusions",
    "title": "Binary Logistic Regression",
    "section": "Conclusions",
    "text": "Conclusions\nModel 1 was a better predictor of species between the two models. Model 1 determined the species based on height, canopy length, canopy width, and number of leaves, which shows that canopy length does matter since Model 2 excluded this variable.\nModel 1 accurately predicted 91% of the observations for Saw Palmetto (Serenoa repens) and 93% for Scrub Palmetto (Sabal etonia)."
  },
  {
    "objectID": "posts/2024-02-10-sentiment-analysis/index.html",
    "href": "posts/2024-02-10-sentiment-analysis/index.html",
    "title": "Text Sentiment Analysis",
    "section": "",
    "text": "First edition dust cover jacket of East of Eden (1952) by American author John Steinbeck. Photo retrieved from Wikipedia page."
  },
  {
    "objectID": "posts/2024-02-10-sentiment-analysis/index.html#overview",
    "href": "posts/2024-02-10-sentiment-analysis/index.html#overview",
    "title": "Text Sentiment Analysis",
    "section": "Overview",
    "text": "Overview\nIn this report, I analyze John Steinbeck’s classic novel, “East of Eden”, to determine the most frequently used words and overall sentiments throughout the book. Figure 1 displays the most frequently used words in each chapter for Chapters 1 - 16, and Figure 2 visualizes a cloud map of most frequenlty used word for just Chapter 1. Figures 3 and 4 portrays the sentiment analysis for Chapters 1-16."
  },
  {
    "objectID": "posts/2024-02-10-sentiment-analysis/index.html#text-analysis",
    "href": "posts/2024-02-10-sentiment-analysis/index.html#text-analysis",
    "title": "Text Sentiment Analysis",
    "section": "Text Analysis",
    "text": "Text Analysis\n\nLoad libraries needed for analysis\nLoad in the pdf of “East of Eden”\nConvert the pdf text into a data frame\nWrangle the data to get tokens into tidy format and remove stop words\nDetermine word counts by chapter\nPlot it in a bar graph\n\n\n\nCode\n### Load Packages\n\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(pdftools)\nlibrary(ggwordcloud)\nlibrary(textdata)\n\n\n\n\nCode\n### Get East of Eden Script loaded in\n\neoe_text &lt;- pdftools::pdf_text(here::here('posts', '2024-02-10-sentiment-analysis','data', 'East-of-Eden.pdf'))\n\n\n\n\nCode\n### Get PDF script text into a data frame\n\neoe_lines &lt;- data.frame(eoe_text) %&gt;% \n  mutate(page = 1:n()) %&gt;%\n  mutate(text_full = str_split(eoe_text, pattern = '\\\\n')) %&gt;% \n  unnest(text_full) %&gt;% \n  mutate(text_full = str_trim(text_full)) \n\n\n\n\nCode\neoe_chapts &lt;- eoe_lines %&gt;% \n  slice(-(1:247)) %&gt;% \n  mutate(chapter = ifelse(str_detect(text_full, \"Chapter\"), text_full, NA)) %&gt;% \n  fill(chapter, .direction = 'down') %&gt;% \n  separate(col = chapter, into = c(\"ch\", \"num\"), sep = \" \") %&gt;% \n  mutate(chapter = as.numeric(as.roman(num)))\n\n\n\n\nCode\neoe_words &lt;- eoe_chapts %&gt;% \n  unnest_tokens(word, text_full) %&gt;% \n  select(-eoe_text)\n\n\n\n\nCode\neoe_wordcount &lt;- eoe_words %&gt;% \n  count(chapter, word)\n\nwordcount_clean &lt;- eoe_wordcount %&gt;% \n  anti_join(stop_words, by = 'word')\n\n\n\n\nCode\ntop_5_words &lt;- wordcount_clean %&gt;% \n  filter(chapter == 1:16) %&gt;% \n  group_by(chapter) %&gt;% \n  arrange(-n) %&gt;% \n  slice(1:5) %&gt;%\n  ungroup()\n\n# Make some graphs: \nggplot(data = top_5_words, aes(x = n, y = word)) +\n  geom_col(fill = \"darkgreen\") +\n  facet_wrap(~chapter, scales = \"free\")+\n  theme_minimal()+\n  labs(x = \" \", \n       y = \" \")\n\n\n\n\n\nFigure 1: Top 5 Words per Chapter. Figure 1 portrays the top 5 most frequently used words per chapter for chapters 1 through 16. The most commonly used word is ‘Adam’ in Chapter 10."
  },
  {
    "objectID": "posts/2024-02-10-sentiment-analysis/index.html#word-cloud",
    "href": "posts/2024-02-10-sentiment-analysis/index.html#word-cloud",
    "title": "Text Sentiment Analysis",
    "section": "Word Cloud",
    "text": "Word Cloud\nCreate a visualization for most frequently used words in Chapter 1:\n\nFilter for only Chapter 1\nDetermine the top 100 most used words\nPlot it\n\n\n\nCode\nch1_top100 &lt;- wordcount_clean %&gt;% \n  filter(chapter == 1) %&gt;% \n  arrange(-n) %&gt;% \n  slice(1:100)\n\n\n\n\nCode\nch1_cloud &lt;- ggplot(data = ch1_top100, aes(label = word)) +\n  geom_text_wordcloud(aes(color = n, size = n), shape = \"diamond\") +\n  scale_size_area(max_size = 6) +\n  scale_color_gradientn(colors = c(\"darkgreen\",\"blue\",\"purple\")) +\n  theme_minimal()\n\nch1_cloud\n\n\n\n\n\nFigure 2: East of Eden Chapter 1 Word Cloud. Fig 2 visualzes the most frequently used words from Chapter 1. As the novel starts out with a thorough description of the setting, the Salinas Valley, there are a lot of words describing the geographical location and physical attributes of Central California."
  },
  {
    "objectID": "posts/2024-02-10-sentiment-analysis/index.html#sentiment-analysis",
    "href": "posts/2024-02-10-sentiment-analysis/index.html#sentiment-analysis",
    "title": "Text Sentiment Analysis",
    "section": "Sentiment Analysis",
    "text": "Sentiment Analysis\nDetermine the overall sentiment (positive or negative) for each chapter:\n\nLoad in the affin lexicon\nBind the affin words to EOE words\nDetermine positive and negative word counts\nPlot it by chapter\nConsider the log ratios and plot it\n\n\n\nCode\nafinn_lex &lt;- get_sentiments(lexicon = \"afinn\")\n### you may be prompted to download an updated lexicon - say yes!\n\n# Let's look at the pretty positive words:\nafinn_pos &lt;- get_sentiments(\"afinn\") %&gt;% \n  filter(value %in% c(3,4,5))\n\n\n\n\nCode\neoe_afinn &lt;- eoe_words %&gt;% \n  filter(chapter == 1:16) %&gt;% \n  inner_join(afinn_lex, by = 'word') ### why inner_join?\n\n\n\n\nCode\nbing_lex &lt;- get_sentiments(lexicon = \"bing\")\n\nnrc_lex &lt;- get_sentiments(lexicon = \"nrc\")\n\neoe_bing &lt;- eoe_words %&gt;% \n  filter(chapter == 1:16) %&gt;% \n  inner_join(bing_lex, by = 'word')\n\nbing_counts &lt;- eoe_bing %&gt;% \n  group_by(chapter, sentiment) %&gt;%\n  summarize(n = n())\n\n# Plot them: \nggplot(data = bing_counts, aes(x = sentiment, y = n, fill = sentiment)) +\n  geom_col() +\n  facet_wrap(~chapter) + \n  labs(\n    x = \" \", \n    y = \"Count\", \n    fill = \"Sentiment\")+\n  scale_fill_manual(values = c(\"positive\" = \"slateblue\", \"negative\" = \"darkred\"))+\n  theme_minimal()\n\n\n\n\n\nFigure 3: East of Eden Sentiment Analysis. Fig 3 portrays the number of words per chapter that are associated with positive or negative connotations. Chapter 3 has the most negative words and Chapter 7 has the most positive words.\n\n\n\n\n\n\nCode\n# find log ratio score overall:\nbing_log_ratio_book &lt;- eoe_bing %&gt;% \n  summarize(n_pos = sum(sentiment == 'positive'),\n            n_neg = sum(sentiment == 'negative'),\n            log_ratio = log(n_pos / n_neg))\n\n# Find the log ratio score by chapter: \nbing_log_ratio_ch &lt;- eoe_bing %&gt;% \n  group_by(chapter) %&gt;% \n  summarize(n_pos = sum(sentiment == 'positive'),\n            n_neg = sum(sentiment == 'negative'),\n            log_ratio = log(n_pos / n_neg)) %&gt;%\n  mutate(log_ratio_adjust = log_ratio - bing_log_ratio_book$log_ratio) %&gt;%\n  mutate(pos_neg = ifelse(log_ratio_adjust &gt; 0, 'pos', 'neg'))\n\nggplot(data = bing_log_ratio_ch, \n       aes(x = log_ratio_adjust,\n           y = fct_rev(factor(chapter)),\n           fill = pos_neg)) +\n           # y = fct_rev(as.factor(chapter)))) +\n  geom_col() +\n  labs(x = 'Adjusted log(positive/negative)',\n       y = 'Chapter number') +\n  scale_fill_manual(values = c('pos' = 'slateblue', 'neg' = 'darkred')) +\n  theme_minimal() +\n  theme(legend.position = 'none')\n\n\n\n\n\nFigure 4: Ratio of Sentiment Analysis. Fig 4 portrays the average sentiment for the whole book and compares each chapter to that average. Based on a log scale, a neutral chapter will equal 0 (ratio = 1), and a super positive chapter will show the same length as a super negative chapter but in the opposite directions. Chapter 2 was the most positive, and Chapters 3 and 9 were very negative."
  },
  {
    "objectID": "posts/2024-02-10-sentiment-analysis/index.html#works-cited",
    "href": "posts/2024-02-10-sentiment-analysis/index.html#works-cited",
    "title": "Text Sentiment Analysis",
    "section": "Works Cited",
    "text": "Works Cited\nSteinbeck, John. East of Eden. Penguin Classics, 2000. Retreived from: https://hitalki.org/blog/wp-content/uploads/2023/05/East-of-Eden.pdf"
  },
  {
    "objectID": "posts/2024-09-21-network-design/index.html",
    "href": "posts/2024-09-21-network-design/index.html",
    "title": "Conservation Network Design",
    "section": "",
    "text": "Peregrine Falcon Release at Morro Rock, Photo Credit: Pacific Coast Peregrine Watch\n\n\nBackground: Raptors and other umbrella species are commonly used in designing reserve networks for biodiversity conservation. Protecting raptors helps safeguard many other species within the same ecosystem. In Morro Bay, creating reserve networks involves balancing various conservation strategies to optimize both ecological and socioeconomic factors. Designing reserve networks based on umbrella species protections can be a cost effective way to achieve conservation goals.\nProblem: Creating a network of reserves in Morro Bay requires consideration of species richness, abundance, and distribution, the costs of land conservation, and the spatial configuration of the network. Optimizing all of these factors is computationally expensive and requires setting numerous species-specific conservation targets. We were interested in assessing the optimal reserve designs when all species (for which we had data) were taken into account, and comparing it with the optimal designs for birds of prey. The level of similarity between the two may indicate whether it is possible to use raptors as umbrella species for reserve design, reducing the need for intensive data collection across many different taxa.\nApproach: Our approach had two components: 1) designing an optimal reserve network for all species, and 2) designing an optimal reserve network for birds of prey. The all-species reserve design included 140 species across a wide array of taxa. The birds of prey reserve design included eight (8) species of raptor: the peregrine falcon (Falco peregrinus anatum), Cooper’s hawk (Accipiter cooperii), ferruginous hawk (Buteo regalis), golden eagle (Aquila chrysaetos), merlin (Falco columbarius), osprey (Pandion haliaetus), prairie falcon (Falco mexicanus), and the sharp-shinned hawk (Accipiter striatus).\nWe used the prioritizr package in R to conduct our analyses and focused on solving Marxan problems, which optimize actions to achieve species conservation targets at the least cost. We used our data on species conservation targets, land planning unit costs, and each species’ presence in each planning unit to set up the initial Marxan problem. We wanted to calculate the optimal reserve design (optimality gap of 0%), as well as a portfolio of 100 reserve design possibilities that were within a small margin of optimal (optimality gap of 15%), so we ran two calculations with these different parameters. To solve the problems once the additional parameters were specified, we used the gurobi solver. In addition, for the portfolio of reserve solutions, we calculated the number of times each planning unit was selected for inclusion in the reserve, representing the frequency of selection and thus the level of priority for conservation of each unit. These analysis steps were conducted for all species first, and then repeated with the selected birds of prey species.\nResults: As shown in Figure 1, the high priority conservation areas (dark blue) for all 140 studied species (panel A) and for the 8 raptors species (panel B) are nearly geographically identical. There are minor differences across low, moderate, and non-priority areas. Nonetheless, Figure 1 conveys that raptors have a similar optimal reserve network when compared to all studied species. When designing reserve networks based on a single optimal solution, as displayed in Figure 2, conservation priority areas across all species (panel A) and for raptors alone (panel B) are nearly identical. Conclusions: Given the similarities between the optimal reserve networks for all studied species and the raptor species, our results suggest that raptors can be used as an umbrella species for Morro Bay reserve design. Utilizing raptors as an umbrella species can reduce the need for intensive data collection across many different taxa and can ultimately achieve the same conservation goals for all species. This conservation strategy will minimize costs and workload while maintaining an adequate level of protection for all studied species. This method of reserve design can create ambiguity for the protection of rare and/or threatened species (such as the California red-legged frog) and may require additional, more specialized protections for these species with unique habitat requirements. Overall, umbrella species can be a cost-effective strategy to optimize conservation efforts in Morro Bay.\n\n\n\nFigure 1. Priority conservation areas in Morro Bay. Land planning units of conservation interest for all studied species (A) and for raptors (B). Each planning unit is color-coded by conservation priority, ranging from non-priority (selected 0 times by optimization algorithm), low priority (selected once), moderate priority (selected 2 or more times), and high priority (selected every time).\n\n\n\n\n\nFigure 2. Priority conservation areas in Morro Bay for an Optimal Solution. Land planning units of conservation interest for all studied species (A) and for raptors (B). Dark blue land planning units are of high conservation priority and light blue planning units are non-priority areas.\n\n\n\n\n\nCitationBibTeX citation:@online{calbert_and_olivia_hemond2024,\n  author = {Calbert and Olivia Hemond, Madison},\n  title = {Conservation {Network} {Design}},\n  date = {2024-09-21},\n  url = {https://madicalbert.github.io/posts/2024-09-21-network-design/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nCalbert and Olivia Hemond, Madison. 2024. “Conservation Network\nDesign.” September 21, 2024. https://madicalbert.github.io/posts/2024-09-21-network-design/."
  },
  {
    "objectID": "posts/2024-09-23-connectivity/index.html",
    "href": "posts/2024-09-23-connectivity/index.html",
    "title": "Habitat Connectivity",
    "section": "",
    "text": "Jaguar in Costa Rican jungle, Photo Credit: Costa Rican Trails\n\n\nBackground: The jaguar (Panthera onca) is a species of big cat found in habitats ranging from the southwestern United States to northern Argentina. They are threatened by the loss and fragmentation of their habitat, along with illegal wildlife trade, illegal trophy hunting, and conflict with humans (USFWS). In Costa Rica, jaguar habitat is protected in nature reserves, but jaguars are not confined to those areas and may move across the landscape to meet their various needs.\nProblem: Identifying key jaguar movement corridors and high-trafficked pinch points will help reserve managers better understand barriers to movement and interactions between the reserves. Connectivity between the reserves is crucial to ensure interbreeding across different jaguar populations. As a threatened species, jaguar connectivity between reserves will ensure species stability and longevity.\nApproach: We used Circuitscape and ArcGIS Pro to analyze jaguar movement in the Talamanca-Osa region of Costa Rica across three conservation reserves: Corcovado, Piedras Blancas, and La Amistad National Parks. These three reserves serve as core areas of jaguar habitat with low levels of human modification. Folger and Brock created a resistance layer (resolution of 390m) by combining features from many data layers including roads, elevation, and land cover and by assigning weighted resistance values to these features based on expert opinion, available data, and literature review. Jaguar least-cost corridors, least-coast pathways, and key movement pinch points between the three reserves were modeled and mapped using Circuitscape. To identify key jaguar corridors and the least cost pathway between the three reserves, we created a map of cost-weighted distances to the three core areas, with a corridor width of 20 cost-weighted km. We visualized the corridors by classifying into 20 quantiles of cost-weighted distances. The least-cost pathway between each pair of reserves was mapped to represent the “best” route for jaguars to take, accounting for both distance traveled and the resistance values of the landscape. To identify key pinch points within corridor areas, we ran Circuitscape across the corridor areas from the previous step. This output displayed areas where corridors are constricted and jaguar movement is funneled through those zones.\nResults: Figure 1 illustrates movement pinch points between Corcovado, Piedras Blancas, and La Amistad National Parks. There is a greater number of pinch points between Corcovado and Piedras Blancas than between Piedras Blancas and La Amistad. Corridors and least-cost pathways between reserves are shown in Figure 2. Between Corcovado and Piedras Blancas, the least-cost pathway makes a slight northward arc. Between Piedras Blancas and La Amistad, the least-cost pathway is a fairly straight line, with slight deviations to either side.\nConclusions: The many movement pinch points between Corcovado and Piedras Blancas represent areas that may be critical for jaguar movement. Development or land conversion in those areas could threaten the ability of jaguars to disperse between the two parks. The pinch points that intersect with the least-cost pathway may be particularly high-trafficked areas by jaguars. If jaguars are funneled through a narrow corridor, that puts them more at risk of coming into contact with each other and potentially causing territorial conflicts (USFWS). Similarly, there may be a high risk of human-jaguar conflict along the least-cost path. Managers should prioritize the maintenance of connectivity between the two reserves, as well as consider protecting other movement corridors to reduce the severity of pinch points. Between Piedras Blancas and La Amistad, there are very few pinch points. This indicates that there is homogeneity in the habitat quality between those two areas, with no particular pathway being easier for a jaguar to take. It does not indicate whether or not that habitat is suitable for jaguars to move through, but we can assume that it is of poor quality, given the background information that jaguars are not frequently observed to move between those two parks. Thus it should be a priority to increase connectivity between those two reserves to ensure long-term jaguar population viability. In future research, it could be beneficial to use collar tracking or camera trap data to map pathways that jaguars actually use, and compare these to the simulated least-cost paths, to create a better-informed picture of jaguar movement between the reserves.\n\n\n\nFigure 1. Jaguar Corridor Pinch Points. Movement pathways of jaguars across three conservation reserves: Corcovado, Piedras Blancas, and La Amistad National Parks. Increased pinch points between Corcovado and Piedras Blancas in comparison to Piedras Blancas and La Amistad.\n\n\n\n\n\nFigure 2. Jaguar movement corridors and least-cost pathways. Movement corridors between Corcovado, Piedras Blancas, and La Amistad National Parks color-coded by cost-weighted distance (lighter = lower cost, darker = higher cost). The least-cost pathway between each pair of reserves is overlaid as a black line.\n\n\nCitations: USFWS. Panthera onca | U.S. Fish & Wildlife Service. (n.d.). FWS.gov. https://www.fws.gov/species/jaguar-panthera-onca\n\n\n\nCitationBibTeX citation:@online{calbert_and_olivia_hemond2024,\n  author = {Calbert and Olivia Hemond, Madison},\n  title = {Habitat {Connectivity}},\n  date = {2024-09-23},\n  url = {https://madicalbert.github.io/posts/2024-09-23-connectivity/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nCalbert and Olivia Hemond, Madison. 2024. “Habitat\nConnectivity.” September 23, 2024. https://madicalbert.github.io/posts/2024-09-23-connectivity/."
  },
  {
    "objectID": "posts/2024-09-20-hotspots/index.html",
    "href": "posts/2024-09-20-hotspots/index.html",
    "title": "Biodiversity Hotspots",
    "section": "",
    "text": "California Sea Lions (Zalophus californianus), Photo Credit: naturepl.com / Franco Banf\n\n\nBackground: Effective allocation of conservation resources for the California sea lion (Zalophus californianus) and Steller sea lion (Eumetopias jubatus) hinges on identifying areas of high conservation priority. Distinguishing between “hotspots,” which represent regions with high species richness under high threat levels, and coldspots, areas of similarly high species richness with lower associated threats, is key to this process. Hotspots may demand more urgent attention, while coldspots may represent zones of population stability, potentially serving as long-term refugia. In this study, we considered a range of threats to sea lion populations, as detailed in Appendix A.\nProblem: Strategic conservation planning often involves reconciling different stakeholder priorities. A key debate centers on whether to allocate limited resources toward conserving areas of high biodiversity that are under immediate threat (hotspots) or protecting species-rich regions that face fewer immediate risks (coldspots). With constraints on both funding and capacity, it is crucial to adopt a data-driven approach that balances these competing objectives.\nApproach: We began by importing the pre-prepared species distribution layers for California sea lions and Steller sea lions into ArcGIS Pro. After verifying consistent spatial projection (WGS84), we created a comprehensive species richness layer by summing the individual species distribution layers. Probabilities were converted to binary presence/absence data, where presence (1) represented the upper 50th percentile and absence (0) the lower 50th percentile. “No data” cells were recoded as 0 to simplify subsequent raster calculations.\nThe combined species richness layer was then simplified to show areas of presence for either or both species. Specifically, values of 0 were reclassified as ‘NODATA,’ and values of 1 and 2 (indicating the presence of one or both species) were reclassified as 1.\nNext, a threat layer was introduced, representing the cumulative impact of various threats on the marine environment. This layer was categorized into five equal-area quantiles, from which we generated a high-threat layer by reclassifying all but the highest quantile to ‘NODATA.’ We used the same process to create a low-threat layer, isolating the lowest quantile. We ensured consistency by matching cell size and extent between the threat and species richness layers. Finally, we intersected the high and low-threat rasters with the sea lion species richness layer to show areas of high-threat (hotspots) and low-threat (coldspots) relative to sea lion distribution.\nResults: As shown in Figure 1, sea lion hotspots are concentrated in the northern portion of their range, particularly along the Pacific Northwest coast. In contrast, cold spots are predominantly found in the southern portion of the species range, off the coast of Southern California and Baja.\nConclusions: Our results present a clear distinction in the distribution of threats relative to areas with high sea lion species richness. The northern population is under greater threat and, therefore, may require more urgent conservation action. To mitigate these risks, conservation efforts should be focused in the northern range where more biodiverse populations are facing greater threats. However, it is also important to consider conservation actions in coldspots to prevent future threats, and ensure population resilience. Additionally, safeguarding coldspot zones may create refuge areas for sea lions, helping to maintain overall population stability.\n\n\n\nFigure 1. Sealion (Zalophus californianus and Eumetopias jubatus) Hotspots and Coldspots. Red represents hotspots or areas with high sealion biodiversity and high threat. Blue represents the coldspots or areas with high sealion biodiversity and low threat.\n\n\n\n\n\nFigure 2. Hotspots and Coldspots for All Species and All Threats. Pink represents the hotspots or areas with high biodiversity and high threat. Blue represents the coldspots or areas with high biodiversity and low threat.\n\n\nAppendix A\nAll threats include:\n\nOcean Acidification\nBeach Access\nCoastal Engineering\nOcean Deposition\nInorganic Pollution\nInvasive Species\nLight Pollution\nNutrient runnoff\nOcean Engineering\nOrganic Pollution\nFish Farming\nOcean Based Pollution\nPower Plants\nSediment runnoff increase\nSediment runnoff decrease\nShipping\nSea Surface Temperature Change\nCoastal Waste\nUltraviolet Radiation Change\nFishing: Demersal Destructive\nFishing: Demersal Non-Destructive High-Bycatch\nFishing: Demersal Non-Destructive Low-Bycatch\nFishing: Pelagic High-Bycatch\nFishing: Pelagic Low-Bycatch Fishing: Recreational\n\n\n\n\nCitationBibTeX citation:@online{calbert_and_natalie_smith2024,\n  author = {Calbert and Natalie Smith, Madison},\n  title = {Biodiversity {Hotspots}},\n  date = {2024-09-20},\n  url = {https://madicalbert.github.io/posts/2024-09-20-hotspots/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nCalbert and Natalie Smith, Madison. 2024. “Biodiversity\nHotspots.” September 20, 2024. https://madicalbert.github.io/posts/2024-09-20-hotspots/."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Madison Calbert",
    "section": "",
    "text": "Hello, I am a conservation ecologist who loves plants and wildlife."
  },
  {
    "objectID": "index.html#welcome--",
    "href": "index.html#welcome--",
    "title": "Madison Calbert",
    "section": "",
    "text": "Hello, I am a conservation ecologist who loves plants and wildlife."
  },
  {
    "objectID": "index.html#professional-interests",
    "href": "index.html#professional-interests",
    "title": "Madison Calbert",
    "section": "Professional Interests",
    "text": "Professional Interests\nWildlife Conservation | Restoration Ecology | Landscape Ecology | Habitat Connectivity | Endangered Species Management & Recovery"
  },
  {
    "objectID": "index.html#skillsets",
    "href": "index.html#skillsets",
    "title": "Madison Calbert",
    "section": "Skillsets",
    "text": "Skillsets\nWildlife & Plant ID | Data Science | Geospatial Analysis | Excel | Project Management | Communication | Stakeholder Engagement"
  },
  {
    "objectID": "index.html#recent-ongoing-projects",
    "href": "index.html#recent-ongoing-projects",
    "title": "Madison Calbert",
    "section": "Recent & Ongoing Projects",
    "text": "Recent & Ongoing Projects\nEvaluating Ecological Conservation Gaps Across a Proposed Sentinel Landscape (Connectivity Analysis)\nValuation of the Restored North Campus Open Space Wetlands\nEvaluating Rapid Response Devices For Island Biosecurity\nGroundwater in Southern California"
  },
  {
    "objectID": "wildlife.html",
    "href": "wildlife.html",
    "title": "Wildlife Photography",
    "section": "",
    "text": "California Tiger Salamander (Ambystoma californiense), Contra Costa County, CA\n\n\n\n\n\n\n\nCalifornia red-legged frog (Rana draytonii), Concord, CA\n\n\n\n\n\n\n\n\n\nWestern toad (Anaxyrus boreas) on a toadstool, Concord, CA\n\n\n\n\n\n\n\nCalifornia slender salamander (Batrachoseps attenuatus), Concord, CA\n\n\n\n\n\n\n\n\n\nJuvenile Western skink (Plestiodon skiltonianus skiltonianus), Goleta, CA\n\n\n\n\n\n\n\nJuvenile Gilbert’s skink (Plestiodon gilberti cancellosus), Concord, CA\n\n\n\n\n\n\n\n\n\nBlunt-nosed leopard lizard (Gambelia sila), Carrizo Plain National Monument (Photo credit: Maddie McGinn)\n\n\n\n\n\n\n\nBlainville’s Horned Lizard (Phrynosoma blainvillii), Carrizo Plain National Monument (Photo credit: Maddie McGinn)\n\n\n\n\n\n\n\n\n\nGopher snake (Pituophis catenifer), Concord, CA\n\n\n\n\n\n\n\nCalifornia glossy snake (Arizona elegans occidentalis), Lakeside, CA\n\n\n\n\n\n\n\n\n\nRing-necked snake (Diadophis punctatus), Goleta, CA\n\n\n\n\n\n\n\nJuvenile California tiger salamander (Ambystoma californiense), San Luis Obispo County"
  },
  {
    "objectID": "wildlife.html#reptiles-amphibians",
    "href": "wildlife.html#reptiles-amphibians",
    "title": "Wildlife Photography",
    "section": "",
    "text": "California Tiger Salamander (Ambystoma californiense), Contra Costa County, CA\n\n\n\n\n\n\n\nCalifornia red-legged frog (Rana draytonii), Concord, CA\n\n\n\n\n\n\n\n\n\nWestern toad (Anaxyrus boreas) on a toadstool, Concord, CA\n\n\n\n\n\n\n\nCalifornia slender salamander (Batrachoseps attenuatus), Concord, CA\n\n\n\n\n\n\n\n\n\nJuvenile Western skink (Plestiodon skiltonianus skiltonianus), Goleta, CA\n\n\n\n\n\n\n\nJuvenile Gilbert’s skink (Plestiodon gilberti cancellosus), Concord, CA\n\n\n\n\n\n\n\n\n\nBlunt-nosed leopard lizard (Gambelia sila), Carrizo Plain National Monument (Photo credit: Maddie McGinn)\n\n\n\n\n\n\n\nBlainville’s Horned Lizard (Phrynosoma blainvillii), Carrizo Plain National Monument (Photo credit: Maddie McGinn)\n\n\n\n\n\n\n\n\n\nGopher snake (Pituophis catenifer), Concord, CA\n\n\n\n\n\n\n\nCalifornia glossy snake (Arizona elegans occidentalis), Lakeside, CA\n\n\n\n\n\n\n\n\n\nRing-necked snake (Diadophis punctatus), Goleta, CA\n\n\n\n\n\n\n\nJuvenile California tiger salamander (Ambystoma californiense), San Luis Obispo County"
  },
  {
    "objectID": "wildlife.html#birds",
    "href": "wildlife.html#birds",
    "title": "Wildlife Photography",
    "section": "Birds",
    "text": "Birds\n\n\n\n\n\n\n\n\n\nGreat blue heron (Ardea herodias), Goleta, CA\n\n\n\n\n\n\n\nAcorn woodpecker (Melanerpes formicivorus), Valley Center, CA\n\n\n\n\n\n\n\n\n\nSong sparrow (Melospiza melodia) nest with two eggs, Bonsall, CA"
  },
  {
    "objectID": "wildlife.html#plants",
    "href": "wildlife.html#plants",
    "title": "Wildlife Photography",
    "section": "Plants",
    "text": "Plants\n\n\n\n\n\n\n\n\n\nSan Diego goldenstar (Bloomeria clevelandii) and purple Chinese houses (Collinsia heterophylla), Lakeside, CA\n\n\n\n\n\n\n\nCalifornia lilac (Ceanothus sp.), Fort Ord, CA\n\n\n\n\n\n\n\n\n\nCalifornia poppy (Eschscholzia californica) and Blue-eyed grass (Sisyrinchium bellum), Santa Barbara, CA\n\n\n\n\n\n\n\nPurple owl’s clover (Castilleja exserta), Concord, CA\n\n\n\n\n\n\n\n\n\nCalifornia poppy (Eschscholzia californica), Santee, CA"
  }
]